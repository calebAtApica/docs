# Data Forwarding Overview

Apica's LogFlow provides centralized control of your observability data pipelines.

Apica's mission is to connect observability data from any source to any destination. We are _**the only platform**_ that provides seamless routing of data, with an attached infinite data reservoir, while providing both _**sequential**,_ _**random access**_ and _**indexed search**_ for all data streams.

<figure><img src="https://logflow-docs.logiq.ai/~gitbook/image?url=https%3A%2F%2F3717450363-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252F8WGNQCWSTnL2NgouIRTq%252Fuploads%252FuouxIjo4je6AdngF3lh2%252Fv2_tr_bg.png%3Falt%3Dmedia%26token%3D57b05df2-9546-4c26-9c24-e7d6eca37a0a&#x26;width=768&#x26;dpr=4&#x26;quality=100&#x26;sign=76db9bd6&#x26;sv=1" alt=""><figcaption></figcaption></figure>

#### Benefits <a href="#benefits" id="benefits"></a>

As data streams arrive, **LogFlow** automatically organizes and optimizes your data flow for your business teams and knowledge workers.

XOps teams can centralize data flow management, gain data EPS control, and increase data quality and relevance. Built on top of any object store, LogFlow’s **InstaStore** enables infinite data retention and on-demand data replay to any target observability platform of your choice.

LogFlow integrates into any enterprise environment with support for a broad array of technologies. This enables teams to ingest data from Applications, Devices, Networks, Operating Systems, IoT Sensors, Web traffic, and more.

Over 1 Trillion log events have been ingested and managed by LogFlow in production customer environments.

#### Watch our introductory video on LogFlow <a href="#watch-our-introductory-video-on-logflow" id="watch-our-introductory-video-on-logflow"></a>

#### Why do you need LogFlow? <a href="#why-do-you-need-logflow" id="why-do-you-need-logflow"></a>

By introducing a pipeline control layer to your existing observability system like Splunk, Datadog, Elastic, etc., LogFlow provides numerous benefits:

1. Reduce response time for any (internal/external) customer data analysis requirement. Data can be sent to any destination on-demand without expensive projects that are common in every enterprise.
2. Most enterprise data can be categorized as critical and non-critical. By eliminating unwanted or non-critical data in target systems like Elastic, Splunk, etc. users can realize savings on the infrastructure and licensing needed, reduce index sizes leading to faster queries, and have higher quality data for knowledge workers.
3. LogFlow stores all its data in [**InstaStore**](https://logflow-docs.logiq.ai/architecture/instastore), our hot store platform built on any object-store. When any data is needed that is not in your target system, LogFlow provides instant replay to your target system on demand
4. Reduce your restricted capital commitments by meaningfully lowering TCO by an average of 55% and gain new investment opportunities to drive competitive initiatives and differentiate your business.

Organizations can comprehensively secure and protect your data far easier than ever by eliminating “blind spots” while enabling 100% of your data to be instantly available for SecOps and DevOps teams. Simplify enterprise oversight and gain new control over data streams. Apica's LogFlow equals strategic empowerment for your digital future with new enterprise agility - never-before-possible control for your strategic and tactical teams to drive change management and meet “what’s next".

## Download Whitepaper

{% file src="../.gitbook/assets/WhitePaper-Observability-Pipeline-Control.pdf" %}

